{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import joblib\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.optimize import minimize\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, StandardScaler, PolynomialFeatures, FunctionTransformer\n",
    "import haversine as hs\n",
    "from haversine import Unit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regression_results(y_test, y_pred):\n",
    "    explained_variance = metrics.explained_variance_score(y_test, y_pred)\n",
    "    mean_absolute_error = metrics.mean_absolute_error(y_test, y_pred) \n",
    "    mse = metrics.mean_squared_error(y_test, y_pred) \n",
    "    median_absolute_error = metrics.median_absolute_error(y_test, y_pred)\n",
    "    r2 = metrics.r2_score(y_test, y_pred)\n",
    "\n",
    "    print('   explained_variance: ', round(explained_variance,4))    \n",
    "    print('   r2: ', round(r2,4))\n",
    "    print('   MAE: ', round(mean_absolute_error,4))\n",
    "    print('   MSE: ', round(mse,4))\n",
    "    print('   RMSE: ', round(np.sqrt(metrics.mean_squared_error(y_test, y_pred)),4))\n",
    "\n",
    "def save_model(model, name):\n",
    "    rmse = str(int(np.sqrt(metrics.mean_squared_error(y_test, y_pred))))\n",
    "    path = \"../models/\" + rmse + \"_RMSE_\" + str(name)\n",
    "    joblib.dump(model, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_lng</th>\n",
       "      <th>y_lat</th>\n",
       "      <th>X_lng</th>\n",
       "      <th>X_lat</th>\n",
       "      <th>snr</th>\n",
       "      <th>rssi</th>\n",
       "      <th>spreading</th>\n",
       "      <th>frequency</th>\n",
       "      <th>distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12.053189</td>\n",
       "      <td>47.477710</td>\n",
       "      <td>12.166732</td>\n",
       "      <td>47.584275</td>\n",
       "      <td>6.0</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>0</td>\n",
       "      <td>868.099976</td>\n",
       "      <td>14597.243233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12.053189</td>\n",
       "      <td>47.477714</td>\n",
       "      <td>12.166732</td>\n",
       "      <td>47.584275</td>\n",
       "      <td>5.5</td>\n",
       "      <td>-101.0</td>\n",
       "      <td>0</td>\n",
       "      <td>868.299988</td>\n",
       "      <td>14596.845865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12.053189</td>\n",
       "      <td>47.477714</td>\n",
       "      <td>12.166732</td>\n",
       "      <td>47.584275</td>\n",
       "      <td>3.8</td>\n",
       "      <td>-102.0</td>\n",
       "      <td>0</td>\n",
       "      <td>868.299988</td>\n",
       "      <td>14596.845865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12.000000</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>12.176353</td>\n",
       "      <td>47.587865</td>\n",
       "      <td>-14.5</td>\n",
       "      <td>-121.0</td>\n",
       "      <td>0</td>\n",
       "      <td>868.099976</td>\n",
       "      <td>66706.964978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12.053189</td>\n",
       "      <td>47.477714</td>\n",
       "      <td>12.176353</td>\n",
       "      <td>47.587865</td>\n",
       "      <td>-14.8</td>\n",
       "      <td>-121.0</td>\n",
       "      <td>0</td>\n",
       "      <td>868.500000</td>\n",
       "      <td>15346.594383</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       y_lng      y_lat      X_lng      X_lat   snr   rssi  spreading  \\\n",
       "0  12.053189  47.477710  12.166732  47.584275   6.0 -100.0          0   \n",
       "1  12.053189  47.477714  12.166732  47.584275   5.5 -101.0          0   \n",
       "2  12.053189  47.477714  12.166732  47.584275   3.8 -102.0          0   \n",
       "3  12.000000  47.000000  12.176353  47.587865 -14.5 -121.0          0   \n",
       "4  12.053189  47.477714  12.176353  47.587865 -14.8 -121.0          0   \n",
       "\n",
       "    frequency      distance  \n",
       "0  868.099976  14597.243233  \n",
       "1  868.299988  14596.845865  \n",
       "2  868.299988  14596.845865  \n",
       "3  868.099976  66706.964978  \n",
       "4  868.500000  15346.594383  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../data/raw/lorapos-integration-data.csv\", decimal=\",\")\n",
    "data = []\n",
    "\n",
    "for i in range(len(df)):\n",
    "    hotspot = json.loads(df.hotspots[i])[0]\n",
    "    d = [\n",
    "        df.node_lng[i], \n",
    "        df.node_lat[i],\n",
    "        hotspot[\"long\"],\n",
    "        hotspot[\"lat\"],\n",
    "        hotspot[\"snr\"], \n",
    "        hotspot[\"rssi\"], \n",
    "        hotspot[\"spreading\"], \n",
    "        hotspot[\"frequency\"], \n",
    "        hs.haversine((df.node_lat[i], df.node_lng[i]),(hotspot[\"lat\"], hotspot[\"long\"]),unit=hs.Unit.METERS)\n",
    "    ]\n",
    "    data.append(d)\n",
    "\n",
    "df = pd.DataFrame(data, columns=[\"y_lng\", \"y_lat\", \"X_lng\", \"X_lat\", \"snr\", \"rssi\", \"spreading\", \"frequency\", \"distance\"])\n",
    "label = LabelEncoder()\n",
    "df[\"spreading\"] = label.fit_transform(df[\"spreading\"])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>snr</th>\n",
       "      <th>rssi</th>\n",
       "      <th>spreading</th>\n",
       "      <th>frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.0</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>0</td>\n",
       "      <td>868.099976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.5</td>\n",
       "      <td>-101.0</td>\n",
       "      <td>0</td>\n",
       "      <td>868.299988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.8</td>\n",
       "      <td>-102.0</td>\n",
       "      <td>0</td>\n",
       "      <td>868.299988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-14.5</td>\n",
       "      <td>-121.0</td>\n",
       "      <td>0</td>\n",
       "      <td>868.099976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-14.8</td>\n",
       "      <td>-121.0</td>\n",
       "      <td>0</td>\n",
       "      <td>868.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3619</th>\n",
       "      <td>-17.0</td>\n",
       "      <td>-133.0</td>\n",
       "      <td>0</td>\n",
       "      <td>868.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3620</th>\n",
       "      <td>-17.0</td>\n",
       "      <td>-133.0</td>\n",
       "      <td>0</td>\n",
       "      <td>868.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3621</th>\n",
       "      <td>-17.0</td>\n",
       "      <td>-133.0</td>\n",
       "      <td>0</td>\n",
       "      <td>868.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3622</th>\n",
       "      <td>-17.0</td>\n",
       "      <td>-133.0</td>\n",
       "      <td>0</td>\n",
       "      <td>868.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3623</th>\n",
       "      <td>-17.0</td>\n",
       "      <td>-133.0</td>\n",
       "      <td>0</td>\n",
       "      <td>868.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3624 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       snr   rssi  spreading   frequency\n",
       "0      6.0 -100.0          0  868.099976\n",
       "1      5.5 -101.0          0  868.299988\n",
       "2      3.8 -102.0          0  868.299988\n",
       "3    -14.5 -121.0          0  868.099976\n",
       "4    -14.8 -121.0          0  868.500000\n",
       "...    ...    ...        ...         ...\n",
       "3619 -17.0 -133.0          0  868.500000\n",
       "3620 -17.0 -133.0          0  868.500000\n",
       "3621 -17.0 -133.0          0  868.500000\n",
       "3622 -17.0 -133.0          0  868.500000\n",
       "3623 -17.0 -133.0          0  868.500000\n",
       "\n",
       "[3624 rows x 4 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = df[\"distance\"]\n",
    "X = df.drop([\"distance\", \"y_lng\", \"y_lat\", \"X_lng\", \"X_lat\"], axis=1)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=1007486)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   explained_variance:  0.287\n",
      "   r2:  0.2855\n",
      "   MAE:  403.9021\n",
      "   MSE:  9649843.0535\n",
      "   RMSE:  3106.4197\n"
     ]
    }
   ],
   "source": [
    "lin = LinearRegression()\n",
    "lin.fit(X_train, y_train)\n",
    "y_pred = lin.predict(X_test)\n",
    "save_model(lin, name=\"LinearRegression\")\n",
    "regression_results(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   explained_variance:  0.433\n",
      "   r2:  0.4302\n",
      "   MAE:  347.5442\n",
      "   MSE:  7694820.2517\n",
      "   RMSE:  2773.9539\n"
     ]
    }
   ],
   "source": [
    "poly_transformer = PolynomialFeatures(degree=2)\n",
    "X_poly_train = poly_transformer.fit_transform(X_train)\n",
    "X_poly_test = poly_transformer.fit_transform(X_test)\n",
    "linear_regressor = LinearRegression()\n",
    "linear_regressor.fit(X_poly_train, y_train)\n",
    "y_pred = linear_regressor.predict(X_poly_test)\n",
    "save_model(linear_regressor, name=\"LinearRegression_PolynomialFeatures\")\n",
    "regression_results(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   explained_variance:  0.3301\n",
      "   r2:  0.3284\n",
      "   MAE:  384.8964\n",
      "   MSE:  9070742.729\n",
      "   RMSE:  3011.7674\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\Python\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but FunctionTransformer was fitted without feature names\n",
      "  warnings.warn(\n",
      "f:\\Python\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but FunctionTransformer was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "funktion_transformer = FunctionTransformer(np.log1p, validate=True)\n",
    "\n",
    "X_log_train = X_train.copy()\n",
    "X_log_train[\"rssi\"] = X_log_train[\"rssi\"]*-1\n",
    "X_log_train[\"snr\"] = X_log_train[\"snr\"]**2\n",
    "\n",
    "X_log_test = X_test.copy()\n",
    "X_log_test[\"rssi\"] = X_log_test[\"rssi\"]*-1\n",
    "X_log_test[\"snr\"] = X_log_test[\"snr\"]**2\n",
    "\n",
    "X_log_train = funktion_transformer.transform(X_log_train)\n",
    "X_log_test = funktion_transformer.transform(X_log_test)\n",
    "\n",
    "linear_regressor = LinearRegression()\n",
    "linear_regressor.fit(X_log_train, y_train)\n",
    "y_pred = linear_regressor.predict(X_log_test)\n",
    "\n",
    "save_model(linear_regressor, name=\"LinearRegression_FunctionTransformer\")\n",
    "regression_results(y_test, y_pred)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   explained_variance:  0.419\n",
      "   r2:  0.4168\n",
      "   MAE:  256.9121\n",
      "   MSE:  7875813.4604\n",
      "   RMSE:  2806.388\n"
     ]
    }
   ],
   "source": [
    "random_forest_regression = RandomForestRegressor(n_estimators=100, max_depth=20)\n",
    "random_forest_regression.fit(X_train, y_train)\n",
    "y_pred = random_forest_regression.predict(X_test)\n",
    "\n",
    "save_model(random_forest_regression, name=\"RandomForestRegressor\")\n",
    "regression_results(y_test, y_pred)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Randomized Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   explained_variance:  0.3478\n",
      "   r2:  0.3459\n",
      "   MAE:  290.767\n",
      "   MSE:  8833135.6948\n",
      "   RMSE:  2972.0592\n",
      "{'estimator__n_estimators': 150, 'estimator__min_samples_split': 34, 'estimator__min_samples_leaf': 7, 'estimator__max_features': 'sqrt', 'estimator__max_depth': 4, 'estimator__criterion': 'squared_error'}\n"
     ]
    }
   ],
   "source": [
    "rf  = Pipeline(\n",
    "    steps=[\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"estimator\", RandomForestRegressor(warm_start=True, oob_score=True))\n",
    "    ]\n",
    ")\n",
    "\n",
    "rgrid = {\n",
    "    \"estimator__n_estimators\": np.arange(50,500,10),\n",
    "    \"estimator__criterion\": [\"squared_error\", \"absolute_error\", \"poisson\"],\n",
    "    \"estimator__min_samples_split\":np.arange(1, 50),\n",
    "    \"estimator__min_samples_leaf\":np.arange(1, 50),\n",
    "    \"estimator__max_features\": [\"sqrt\", \"log2\"],\n",
    "    \"estimator__max_depth\": np.arange(2, 20)\n",
    "}\n",
    "\n",
    "\n",
    "opt_rf = RandomizedSearchCV(rf, rgrid, cv = 5, scoring=\"neg_root_mean_squared_error\", random_state=1007486)\n",
    "opt_rf.fit(X_train, y_train)\n",
    "y_pred = opt_rf.predict(X_test)\n",
    "save_model(opt_rf, name=\"RandomForestRegressor_RandomizedSearchCV\")\n",
    "regression_results(y_test, y_pred)\n",
    "print(opt_rf.best_params_)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gridsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   explained_variance:  0.416\n",
      "   r2:  0.4139\n",
      "   MAE:  257.4149\n",
      "   MSE:  7915651.3475\n",
      "   RMSE:  2813.4767\n",
      "{'estimator__max_depth': 7, 'estimator__n_estimators': 80}\n"
     ]
    }
   ],
   "source": [
    "rf  = Pipeline(\n",
    "    steps=[\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"estimator\", RandomForestRegressor(warm_start=True, oob_score=True))\n",
    "    ]\n",
    ")\n",
    "\n",
    "rgrid = {\n",
    "    \"estimator__n_estimators\": np.arange(50,200,10),\n",
    "    \"estimator__max_depth\": np.arange(2, 20)\n",
    "}\n",
    "\n",
    "\n",
    "opt_rf = GridSearchCV(rf, rgrid, cv = 5, scoring=\"neg_root_mean_squared_error\")\n",
    "opt_rf.fit(X_train, y_train)\n",
    "y_pred = opt_rf.predict(X_test)\n",
    "save_model(opt_rf, name=\"RandomForestRegressor_GridSearchCV\")\n",
    "regression_results(y_test, y_pred)\n",
    "print(opt_rf.best_params_)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   explained_variance:  0.4466\n",
      "   r2:  0.4449\n",
      "   MAE:  244.7348\n",
      "   MSE:  7496472.5269\n",
      "   RMSE:  2737.9687\n",
      "{'estimator__n_estimators': 290, 'estimator__min_samples_split': 0.7900000202020202, 'estimator__max_features': 'sqrt', 'estimator__max_depth': 7, 'estimator__loss': 'squared_error', 'estimator__learning_rate': 0.08246938775510204}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "pipeline = Pipeline(\n",
    "    steps=[\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"estimator\", GradientBoostingRegressor())\n",
    "    ]\n",
    ")\n",
    "\n",
    "grid = {\n",
    "    \"estimator__n_estimators\": np.arange(10,500,10),\n",
    "    \"estimator__learning_rate\": np.linspace(1e-3, 0.5,50),\n",
    "    \"estimator__max_depth\": np.arange(1,15), \n",
    "    \"estimator__min_samples_split\": np.linspace(1e-7, 0.99,100),\n",
    "    \"estimator__max_features\": [\"sqrt\", \"log2\"],\n",
    "    \"estimator__loss\": [\"squared_error\", \"absolute_error\", \"huber\", \"quantile\"]\n",
    "}\n",
    "\n",
    "gbt_grid = RandomizedSearchCV(pipeline, grid, cv=5,scoring=\"neg_root_mean_squared_error\", random_state=1007486)\n",
    "\n",
    "gbt_grid.fit(X_train, y_train)\n",
    "y_pred = gbt_grid.predict(X_test)\n",
    "save_model(gbt_grid, name=\"GradientBoostingRegressor\")\n",
    "regression_results(y_test, y_pred)\n",
    "print(gbt_grid.best_params_)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\Python\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:559: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "f:\\Python\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:559: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   explained_variance:  0.4595\n",
      "   r2:  0.4576\n",
      "   MAE:  268.0448\n",
      "   MSE:  7325858.0788\n",
      "   RMSE:  2706.6322\n",
      "{'MLPRegressor__activation': 'relu', 'MLPRegressor__hidden_layer_sizes': (4, 2), 'MLPRegressor__solver': 'lbfgs'}\n"
     ]
    }
   ],
   "source": [
    "pipe_MLPRegressor = Pipeline(\n",
    "    [\n",
    "        ('scaler',  StandardScaler()),\n",
    "        ('MLPRegressor', MLPRegressor(random_state = 42, max_iter=1000))\n",
    "    ]\n",
    ")\n",
    "\n",
    "grid_params_MLPRegressor = [{\n",
    "    'MLPRegressor__solver': ['lbfgs'],\n",
    "    'MLPRegressor__activation' : ['relu','logistic','tanh'],\n",
    "    'MLPRegressor__hidden_layer_sizes':[(2,), (4,),(2,2),(4,4),(4,2),(10,10),(2,\n",
    "2,2)],}]\n",
    "\n",
    "CV_mlpregressor = GridSearchCV(estimator = pipe_MLPRegressor, param_grid = grid_params_MLPRegressor, cv = 5, return_train_score=True, verbose=0)\n",
    "\n",
    "CV_mlpregressor.fit(X_train, y_train)\n",
    "y_pred = CV_mlpregressor.predict(X_test)\n",
    "save_model(gbt_grid, name=\"NeuralNetwork\")\n",
    "regression_results(y_test, y_pred)\n",
    "print(CV_mlpregressor.best_params_)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\Python\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "5 fits failed out of a total of 50.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"f:\\Python\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"f:\\Python\\lib\\site-packages\\sklearn\\pipeline.py\", line 382, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"f:\\Python\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 476, in fit\n",
      "    trees = Parallel(\n",
      "  File \"f:\\Python\\lib\\site-packages\\joblib\\parallel.py\", line 1085, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"f:\\Python\\lib\\site-packages\\joblib\\parallel.py\", line 901, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"f:\\Python\\lib\\site-packages\\joblib\\parallel.py\", line 819, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"f:\\Python\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"f:\\Python\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 597, in __init__\n",
      "    self.results = batch()\n",
      "  File \"f:\\Python\\lib\\site-packages\\joblib\\parallel.py\", line 288, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"f:\\Python\\lib\\site-packages\\joblib\\parallel.py\", line 288, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"f:\\Python\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 117, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"f:\\Python\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 189, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"f:\\Python\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1342, in fit\n",
      "    super().fit(\n",
      "  File \"f:\\Python\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 265, in fit\n",
      "    check_scalar(\n",
      "  File \"f:\\Python\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 1480, in check_scalar\n",
      "    raise ValueError(\n",
      "ValueError: min_samples_split == 1, must be >= 2.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "f:\\Python\\lib\\site-packages\\sklearn\\model_selection\\_search.py:953: UserWarning: One or more of the test scores are non-finite: [ -964.77830492 -1059.89030755 -1364.06145134            nan\n",
      "  -961.52839356  -755.29294981 -1027.97828248 -1061.58108973\n",
      " -1489.75086047 -1033.13789886]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   explained_variance:  0.4372\n",
      "   r2:  0.4357\n",
      "   MAE:  259.9988\n",
      "   MSE:  7620983.9725\n",
      "   RMSE:  2760.613\n",
      "{'estimator__n_estimators': 360, 'estimator__min_samples_split': 8, 'estimator__min_samples_leaf': 19, 'estimator__max_features': 'sqrt', 'estimator__max_depth': 11, 'estimator__criterion': 'absolute_error', 'decomposer__n_components': 3}\n"
     ]
    }
   ],
   "source": [
    "rf  = Pipeline(\n",
    "    steps=[\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"decomposer\", PCA()),\n",
    "        (\"estimator\", RandomForestRegressor(warm_start=True, oob_score=True))\n",
    "    ]\n",
    ")\n",
    "\n",
    "rgrid = {\n",
    "    \"estimator__n_estimators\": np.arange(50,500,10),\n",
    "    \"estimator__criterion\": [\"squared_error\", \"absolute_error\", \"poisson\"],\n",
    "    \"estimator__min_samples_split\":np.arange(1, 50),\n",
    "    \"estimator__min_samples_leaf\":np.arange(1, 50),\n",
    "    \"estimator__max_features\": [\"sqrt\", \"log2\"],\n",
    "    \"estimator__max_depth\": np.arange(2, 20), \n",
    "    \"decomposer__n_components\": np.arange(1, 6)\n",
    "}\n",
    "\n",
    "\n",
    "opt_rf = RandomizedSearchCV(rf, rgrid, cv = 5, scoring=\"neg_root_mean_squared_error\", random_state=1007486)\n",
    "opt_rf.fit(X_train, y_train)\n",
    "y_pred = opt_rf.predict(X_test)\n",
    "save_model(opt_rf, name=\"RandomForestRegressor_PCA_RandomizedSearchCV\")\n",
    "regression_results(y_test, y_pred)\n",
    "print(opt_rf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\Python\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "10 fits failed out of a total of 50.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "10 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"f:\\Python\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"f:\\Python\\lib\\site-packages\\sklearn\\pipeline.py\", line 378, in fit\n",
      "    Xt = self._fit(X, y, **fit_params_steps)\n",
      "  File \"f:\\Python\\lib\\site-packages\\sklearn\\pipeline.py\", line 336, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "  File \"f:\\Python\\lib\\site-packages\\joblib\\memory.py\", line 349, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"f:\\Python\\lib\\site-packages\\sklearn\\pipeline.py\", line 870, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "  File \"f:\\Python\\lib\\site-packages\\sklearn\\decomposition\\_pca.py\", line 433, in fit_transform\n",
      "    U, S, Vt = self._fit(X)\n",
      "  File \"f:\\Python\\lib\\site-packages\\sklearn\\decomposition\\_pca.py\", line 483, in _fit\n",
      "    return self._fit_full(X, n_components)\n",
      "  File \"f:\\Python\\lib\\site-packages\\sklearn\\decomposition\\_pca.py\", line 501, in _fit_full\n",
      "    raise ValueError(\n",
      "ValueError: n_components=6 must be between 0 and min(n_samples, n_features)=4 with svd_solver='full'\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "f:\\Python\\lib\\site-packages\\sklearn\\model_selection\\_search.py:953: UserWarning: One or more of the test scores are non-finite: [ -308.42492784            nan  -255.57490071  -830.14533196\n",
      "            nan -1092.29633753  -278.61913558  -273.52695245\n",
      " -1384.57062188 -1500.69674209]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   explained_variance:  0.4571\n",
      "   r2:  0.4557\n",
      "   MAE:  241.707\n",
      "   MSE:  7350827.9633\n",
      "   RMSE:  2711.241\n",
      "{'estimator__n_estimators': 150, 'estimator__min_samples_split': 0.6300000363636363, 'estimator__max_features': 'log2', 'estimator__max_depth': 8, 'estimator__loss': 'squared_error', 'estimator__learning_rate': 0.04173469387755102, 'decomposer__n_components': 4}\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline(\n",
    "    steps=[\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"decomposer\", PCA()),\n",
    "        (\"estimator\", GradientBoostingRegressor())\n",
    "    ]\n",
    ")\n",
    "\n",
    "grid = {\n",
    "    \"estimator__n_estimators\": np.arange(10,500,10),\n",
    "    \"estimator__learning_rate\": np.linspace(1e-3, 0.5,50),\n",
    "    \"estimator__max_depth\": np.arange(1,15), \n",
    "    \"estimator__min_samples_split\": np.linspace(1e-7, 0.99,100),\n",
    "    \"estimator__max_features\": [\"sqrt\", \"log2\"],\n",
    "    \"estimator__loss\": [\"squared_error\", \"absolute_error\", \"huber\", \"quantile\"],\n",
    "    \"decomposer__n_components\": np.arange(1, 7)\n",
    "}\n",
    "\n",
    "gbt_grid = RandomizedSearchCV(pipeline, grid, cv=5,scoring=\"neg_root_mean_squared_error\", random_state=1007486)\n",
    "\n",
    "gbt_grid.fit(X_train, y_train)\n",
    "y_pred = gbt_grid.predict(X_test)\n",
    "save_model(gbt_grid, name=\"GradientBoostingRegressor_PCA_RandomizedSearchCV\")\n",
    "regression_results(y_test, y_pred)\n",
    "print(gbt_grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loaded_model = joblib.load(filename)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7 (tags/v3.10.7:6cc6b13, Sep  5 2022, 14:08:36) [MSC v.1933 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "78f5b707d86fd9281530b9fa2dbdbe1b33232c3b651a8e052360c651d4996094"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
